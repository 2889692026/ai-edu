Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/Microsoft/ai-edu/blob/master/LICENSE.md)版权许可

（未完待续）

# 再谈训练集，验证集，测试集

木头：老师，第就章时您说过测试集的事儿，当时没什么概念，这次果然就用上了。这三个的英文是Training Set, Validation Set, Test Set，对吧？

铁柱：对！其中验证集Validation Set也可以叫开发集（Developer Set）。因为这次我们的手写字符的训练结果，无法用图形化的形式展示其准确程度，所以必须用独立的测试集来测试。注意，不能用测试集的数据去训练哦，否则就违背了神经网络训练的基本准则，自欺欺人了。

木头：啊！这么严重？

铁柱：在实际的生产环境中，Training Set用于训练模型，Validation Set用来统计评估指标，调节参数，选择算法，Test Set最后整体评估模型性能。

木头：那我们在这一章中，为什么没有Validation Set呢？

铁柱：因为我们的这个手写数字识别的问题，模型训练比较简单，一个两层的网络就足够了，参数也没有多少，所以中间的调整训练的过程并不复杂，所以没必要用验证集来帮忙，反而会增加工作复杂度。在一些复杂的模型中，模型可能只对训练数据有效，对验证数据就效果很差，你就根本没必要去用测试集做测试了。

木头：那具体如何使用Validation Set呢？

铁柱：在传统的机器学习中，比如一个SVM，我们经常用交叉验证(Cross Validation)的方法，比如把数据分成10份，V1-V10，其中V1-V9用来训练，V10用来验证。然后用V2-V10做训练，V1做验证......如此我们可以做10次训练和验证，大大增加了模型的可靠性。

木头：好办法！验证集也可以做训练，训练集数据也可以做验证，当样本很少时，这个很有用。那么深度学习中的用法是什么呢？

铁柱：比如在神经网络中，训练时到底迭代多少次停止呢？或者我们设置学习率为多少何时呢？或者用几个中间层，以及每个中间层用几个神经元呢？这些都可以用验证集来解决。在咱们前面的学习中，一般使用diff_loss < 1e-10做为迭代终止条件，虽然在绝大多数情况下可行，但不是绝对的，不能保证随机梯度下降算法陷入局部最优解。此时，我们可以用验证集来验证一下准确率，假设只有90%的的准确率，那可能确实是局部最优解。这样我们可以继续迭代，寻找全局最优解。

木头：那么这三者的比例关系如何调配呢？

铁柱：看下图吧。在传统的机器学习中，三者可以是6:2:2。在深度学习中，一般要求样本数据量很大，所以可以给训练集更多的数据，比如8:1:1。开发集，顾名思义，只给开发人员使用，他们看不到测试集。好比“公检法”三者的关系，公安局（训练集）负责抓坏人（我们抓到了一个模型！），检察院（验证集）负责诉讼（我们认为这个模型还不错！），法院（测试集）负责审判坏人（大锤子一敲：这个模型不好，重新去抓！），

<img src="./Images/10/dataset.jpg"/>

木头：（捂嘴狂笑）老师您以前是...公检法岗位的...？（继续松枝乱颤）

铁柱：笑什么笑！（恨不得真有个大锤子敲木头脑袋一下）讲真，我们还没有学习得到正则化一类的知识，那些参数都是靠验证集来确定的，并不是训练出来的。

木头：（一脸懵）肿么弄？

铁柱：正则化分为L1/L2两种，实际上是在误差函数后面增加一个项，以避免过度拟合。这个项里面有个参数，我们并不知道设置为多少合适，而是从0.01到1之间用验证集去试验训练效果。

木头：那如何知道是过拟合了呢？

铁柱：......啊，问题越来越深了，这个咱们后面遇到时再讲吧。
